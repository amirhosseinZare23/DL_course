{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AmirhosseinZare\n",
        "## chapter 6"
      ],
      "metadata": {
        "id": "d5UCgYDxDT1N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hD4cyOoWDSlr"
      },
      "outputs": [],
      "source": [
        "# Create text\n",
        "text_data = [\"   Interrobang. By Aishwarya Henriette\"\n",
        "             \"Parking And Going. By Karl Gautier\",\n",
        "             \" Today Is The night. By Jarek Prakash   \"]\n",
        "# Strip whitespaces\n",
        "strip_whitespace = [string.strip() for string in text_data]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strip_whitespace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIoMJJ-rDsd2",
        "outputId": "46b013a9-d4ac-4d7c-ef8f-827cc3dc5b0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interrobang. By Aishwarya HenrietteParking And Going. By Karl Gautier',\n",
              " 'Today Is The night. By Jarek Prakash']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strip_whitespace = [string.lstrip() for string in text_data]\n",
        "strip_whitespace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_vaiRvkDuwV",
        "outputId": "09f6c00d-2928-4898-a270-aa52f8a1c47e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Interrobang. By Aishwarya HenrietteParking And Going. By Karl Gautier',\n",
              " 'Today Is The night. By Jarek Prakash   ']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strip_whitespace = [string.rstrip() for string in text_data]\n",
        "strip_whitespace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2FTtv9pDysc",
        "outputId": "49e1fe06-7e8b-41b9-f694-97d690639f86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['   Interrobang. By Aishwarya HenrietteParking And Going. By Karl Gautier',\n",
              " ' Today Is The night. By Jarek Prakash']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove periods\n",
        "remove_periods = [string.replace(\".\", \"\") for string in strip_whitespace]\n",
        "# Show text\n",
        "remove_periods"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg_lN6LmD2TJ",
        "outputId": "53992471-2f9e-44ab-e17e-874125d9e74c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['   Interrobang By Aishwarya HenrietteParking And Going By Karl Gautier',\n",
              " ' Today Is The night By Jarek Prakash']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function\n",
        "def capitalizer(string: str) -> str:\n",
        "  return string.upper()\n",
        "\n",
        "# Apply function\n",
        "[capitalizer(string) for string in remove_periods]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r01eNyjgD5TD",
        "outputId": "66c602ab-7558-44c1-c195-e34dc4889ff2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['   INTERROBANG BY AISHWARYA HENRIETTEPARKING AND GOING BY KARL GAUTIER',\n",
              " ' TODAY IS THE NIGHT BY JAREK PRAKASH']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library\n",
        "import re\n",
        "# Create function\n",
        "\n",
        "def replace_letters_with_X(string: str) -> str:\n",
        "  return re.sub(r\"[a-zA-Z]\", \"X\", string)\n",
        "\n",
        "# Apply function\n",
        "[replace_letters_with_X(string) for string in remove_periods]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEtCuoSqD722",
        "outputId": "6f80faaa-d1fc-4e1b-842c-a5c6a9a8d707"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['   XXXXXXXXXXX XX XXXXXXXXX XXXXXXXXXXXXXXXX XXX XXXXX XX XXXX XXXXXXX',\n",
              " ' XXXXX XX XXX XXXXX XX XXXXX XXXXXXX']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a string\n",
        "s = \"machine learning in python cookbook\"\n",
        "# Find the first index of the letter \"n\"\n",
        "find_n = s.find(\"n\")\n",
        "# Whether or not the string starts with \"m\"\n",
        "starts_with_m = s.startswith(\"m\")\n",
        "# Whether or not the string ends with \"python\"\n",
        "ends_with_python = s.endswith(\"python\")\n",
        "# Is the string alphanumeric\n",
        "is_alnum = s.isalnum()\n",
        "# Is it composed of only alphabetical characters (not including spaces)\n",
        "is_alpha = s.isalpha()\n",
        "# Encode as utf-8\n",
        "encode_as_utf8 = s.encode(\"utf-8\")\n",
        "# Decode the same utf-8\n",
        "decode = encode_as_utf8.decode(\"utf-8\")\n",
        "print(\n",
        "  find_n,\n",
        "  starts_with_m,\n",
        "  ends_with_python,\n",
        "  is_alnum,\n",
        "  is_alpha,\n",
        "  encode_as_utf8,\n",
        "  decode,\n",
        "  sep = \"|\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smyZuh80D_5q",
        "outputId": "79d11766-9d25-4cd0-f706-4c0ac79efb0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5|True|False|False|False|b'machine learning in python cookbook'|machine learning in python cookbook\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "  find_n,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZlpVihVEC-L",
        "outputId": "76a8837c-55b4-4df7-9318-27ada2d44370"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(starts_with_m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsDaSemJEE6n",
        "outputId": "b1b6a93b-5035-472d-b7cb-2a0e92fddb48"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ends_with_python)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf0iwJNrEHBE",
        "outputId": "dc4cbc01-01fe-402d-b9f5-9cf75b39e411"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(is_alnum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXJ-1ihDEIra",
        "outputId": "67d8ad23-297c-4026-8054-13b624302daa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(is_alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqbmQxssEKe5",
        "outputId": "48b28a0d-28d9-4349-9aa9-892b93e974dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "  encode_as_utf8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc6TUhTFEL1N",
        "outputId": "c9e74b9f-e240-4c4d-b4d7-9449414a5baf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'machine learning in python cookbook'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyeb5JBjENoi",
        "outputId": "13ed6141-fe18-4cd8-b78f-2a321c13672f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machine learning in python cookbook\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import unicodedata\n",
        "import sys\n",
        "# Create text\n",
        "text_data = ['Hi!!!! I. Love. This. Song....',\n",
        "'10000% Agree!!!! #LoveIT',\n",
        "'Right?!?!']\n",
        "# Create a dictionary of punctuation characters\n",
        "punctuation = dict.fromkeys(\n",
        "(i for i in range(sys.maxunicode)\n",
        "if unicodedata.category(chr(i)).startswith('P')\n",
        "),\n",
        "None\n",
        ")\n",
        "# For each string, remove any punctuation characters\n",
        "[string.translate(punctuation) for string in text_data]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDVJI5czEPS-",
        "outputId": "ca707952-9298-4d89-eb00-fd09a0dc68f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi I Love This Song', '10000 Agree LoveIT', 'Right']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = {\"water\":\"آب\", \"why\":\"چراااااا\"}"
      ],
      "metadata": {
        "id": "cwUOZeQcERuU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWLDiZcVEUxf",
        "outputId": "7f9ec471-533a-4c4e-80dd-e409b46b853b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'water': 'آب', 'why': 'چراااااا'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = ['why water']"
      ],
      "metadata": {
        "id": "EBJHjSvDEWlu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = {\"water\": \"آب\", \"why\": \"چراااااا\"}\n",
        "\n",
        "s = ['why water']\n",
        "\n",
        "translated = [' '.join([dict1.get(word, word) for word in sentence.split()]) for sentence in s]\n",
        "\n",
        "print(translated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUvwj_j9EY1h",
        "outputId": "bee66c25-eedb-48a9-8a4f-7dd728ec1d1f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['چراااااا آب']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "# Load library\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Create text\n",
        "string = \"The science of today is the technology of tomorrow\"\n",
        "# Tokenize words\n",
        "word_tokenize(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzZuiUYWEdho",
        "outputId": "33703bfc-3127-4fed-865d-7234507ba5ee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.tokenize import sent_tokenize\n",
        "# Create text\n",
        "string = \"The science of today is the technology of tomorrow. Tomorrow is today.\"\n",
        "# Tokenize sentences\n",
        "sent_tokenize(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z-B_v8_Eio3",
        "outputId": "17db775d-c713-4b80-bbbf-fd16d2923f7a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "nltk.download('stopwords')\n",
        "import nltk\n",
        "# Load library\n",
        "from nltk.corpus import stopwords\n",
        "# You will have to download the set of stop words the first time\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# Create word tokens\n",
        "tokenized_words = ['i',\n",
        "                  'am',\n",
        "                  'going',\n",
        "                  'to',\n",
        "                  'go',\n",
        "                  'to',\n",
        "                  'the',\n",
        "                  'store',\n",
        "                  'and',\n",
        "                  'park']\n",
        "# Load stop words\n",
        "stop_words = stopwords.words('english')\n",
        "# Remove stop words\n",
        "[word for word in tokenized_words if word not in stop_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWj9DxmXEm2w",
        "outputId": "83fb05f7-e05e-4008-f994-be4dfff5379d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['going', 'go', 'store', 'park']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo4GWHwlE2Er",
        "outputId": "dead686c-ccf8-45d0-80ec-08e2a65118eb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'about', 'above', 'after', 'again']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load library\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# Create word tokens\n",
        "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
        "# Create stemmer\n",
        "porter = PorterStemmer()\n",
        "# Apply stemmer\n",
        "[porter.stem(word) for word in tokenized_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS7L2QpzE5Wd",
        "outputId": "5c8cf291-4e8b-4f05-a306-1b203f4cdf9f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dt-2pHGPE7XH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}